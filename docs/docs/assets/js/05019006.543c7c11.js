"use strict";(self.webpackChunkmodlib_docs=self.webpackChunkmodlib_docs||[]).push([[174],{5787:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>h,frontMatter:()=>i,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"examples/matcher","title":"Matcher","description":"The Matcher component is designed to identify relationships between two sets of detections based on their spatial overlap. It takes two sets of detections and compares their bounding boxes to determine overlaping area. The matcher.match(set1, set2) method returns a boolean mask indicating which detections in the first set overlap with any detection in the second set.","source":"@site/docs/examples/matcher.md","sourceDirName":"examples","slug":"/examples/matcher","permalink":"/docs/examples/matcher","draft":false,"unlisted":false,"tags":[],"version":"current","lastUpdatedAt":1732531312000,"sidebarPosition":3,"frontMatter":{"title":"Matcher","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Counter","permalink":"/docs/examples/counter"},"next":{"title":"Heatmap","permalink":"/docs/examples/heatmap"}}');var o=n(4848),s=n(8453);const i={title:"Matcher",sidebar_position:3},r="Matcher",c={},d=[];function l(e){const t={a:"a",code:"code",h1:"h1",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"matcher",children:"Matcher"})}),"\n",(0,o.jsxs)(t.p,{children:["The ",(0,o.jsx)(t.a,{href:"../api-reference/apps/matcher#matcher",children:"Matcher"})," component is designed to identify relationships between two sets of detections based on their spatial overlap. It takes two sets of detections and compares their bounding boxes to determine overlaping area. The ",(0,o.jsx)(t.code,{children:"matcher.match(set1, set2)"})," method returns a boolean mask indicating which detections in the first set overlap with any detection in the second set."]}),"\n",(0,o.jsx)(t.p,{children:"The Matcher can be used to identify context-specific relationships, such as:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Determining if a person is holding an object (e.g., a cup)."}),"\n",(0,o.jsx)(t.li,{children:"Verifying if a person is wearing a specific item (e.g., a helmet or safety vest)."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:"Below an example of how one can use the Matcher in the Application Module Library."}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",metastring:'title="matcher.py"',children:'from modlib.apps import Annotator, Matcher\nfrom modlib.devices import AiCamera\nfrom modlib.models.zoo import SSDMobileNetV2FPNLite320x320\n\ndevice = AiCamera()\nmodel = SSDMobileNetV2FPNLite320x320()\ndevice.deploy(model)\n\nmatcher = Matcher()\nannotator = Annotator()\n\nwith device as stream:\n    for frame in stream:\n        detections = frame.detections[frame.detections.confidence > 0.50]\n\n        p = detections[detections.class_id == 0]  # Person\n        c = detections[detections.class_id == 46]  # Cup\n\n        detections = p[matcher.match(p, c)]\n\n        labels = [f"# PERSON & CUP" for _, s, c, _ in detections]\n        annotator.annotate_boxes(frame, detections, labels=labels)\n        frame.display()\n'})}),"\n",(0,o.jsxs)(t.p,{children:["The Matcher achieves improved performance when used in combination with a tracker, such as ",(0,o.jsx)(t.a,{href:"/docs/examples/tracker",children:"BYTETracker"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"Tracklets, which are unique identifiers assigned to tracked objects across frames, provide an additional piece of information to maintain the correlation between the two sets of detections over time. This makes sure that objects are consistently identified across frames, reducing false matches caused by momentary overlaps or shifting detections."}),"\n",(0,o.jsx)(t.p,{children:"An example of how to use the Matcher and Tracker together below:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",metastring:'title="tracker_matcher.py"',children:'from modlib.apps import Annotator, BYTETracker, Matcher\nfrom modlib.devices import AiCamera\nfrom modlib.models.zoo import SSDMobileNetV2FPNLite320x320\n\n\nclass BYTETrackerArgs:\n    track_thresh: float = 0.25\n    track_buffer: int = 30\n    match_thresh: float = 0.8\n    aspect_ratio_thresh: float = 3.0\n    min_box_area: float = 1.0\n    mot20: bool = False\n\n\ndevice = AiCamera()\nmodel = SSDMobileNetV2FPNLite320x320()\ndevice.deploy(model)\n\nmatcher = Matcher()\ntracker = BYTETracker(BYTETrackerArgs())\nannotator = Annotator()\n\nwith device as stream:\n    for frame in stream:\n        detections = frame.detections[frame.detections.confidence > 0.50]\n        detections = tracker.update(frame, detections)\n\n        p = detections[detections.class_id == 0]  # Person\n        c = detections[detections.class_id == 46]  # Cup\n\n        detections = p[matcher.match(p, c)]\n\n        labels = [f"#{t} PERSON & CUP" for _, s, c, t in detections]\n        annotator.annotate_boxes(frame, detections, labels=labels)\n        frame.display()\n'})})]})}function h(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(l,{...e})}):l(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>i,x:()=>r});var a=n(6540);const o={},s=a.createContext(o);function i(e){const t=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);